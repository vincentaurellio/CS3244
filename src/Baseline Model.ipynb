{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d36cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import recall_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043cc78",
   "metadata": {},
   "source": [
    "## 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37ecab-b186-4d34-adef-e557f3715cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets given\n",
    "df_movie_details = pd.read_json(\"../data/IMDB_movie_details.json\", lines = True)\n",
    "df_reviews = pd.read_json(\"../data/IMDB_reviews.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88639b81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_movie_details.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccfc42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['is_spoiler'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_pickle(\"../data/tokenized_reviews.pkl.gz\", compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62430f7",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87377180",
   "metadata": {},
   "source": [
    "### Tokenize review texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9ceae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZING WILL TAKE ~15 MINUTES\n",
    "# If you want to save after tokenizing feel free to do so to save time in tokenizing again\n",
    "df_reviews['tokenized_summary'] = list(map(word_tokenize, df_reviews['review_summary']))\n",
    "df_reviews['tokenized_reviews'] = list(map(word_tokenize, df_reviews['review_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7712e14",
   "metadata": {},
   "source": [
    "### Removing stop words and punctuations from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85064f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stop words\n",
    "stop_words_and_punctuations = set(stopwords.words('english') + list(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words and punctuations from the tokenized list\n",
    "df_reviews['tokenized_summary'] = list(map(lambda x: [word.lower() for word in x if word.lower() not in stop_words_and_punctuations], df_reviews['tokenized_summary']))\n",
    "df_reviews['tokenized_reviews'] = list(map(lambda x: [word.lower() for word in x if word.lower() not in stop_words_and_punctuations], df_reviews['tokenized_reviews']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9702f68",
   "metadata": {},
   "source": [
    "### Stemming or Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem or lemmatise words\n",
    "stemmer = PorterStemmer()\n",
    "df_reviews['tokenized_summary'] = list(map(lambda x: [stemmer.stem(word) for word in x], df_reviews['tokenized_summary']))\n",
    "df_reviews['tokenized_reviews'] = list(map(lambda x: [stemmer.stem(word) for word in x], df_reviews['tokenized_reviews']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2297ac2d",
   "metadata": {},
   "source": [
    "### Return back the cleaned tokenized words into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d90e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews[\"text_tokenized\"] = list(map(lambda x: ' '.join(x), df_reviews['tokenized_reviews']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1fc0f5",
   "metadata": {},
   "source": [
    "### Save the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save changes made to original dataset to save time tokenizing etc\n",
    "df_reviews.to_pickle(\"../data/cleaned_reviews.pkl.gz\", compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8573cb2b",
   "metadata": {},
   "source": [
    "### Undersample non-spoiler movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b8d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_details[\"release_date\"] = pd.to_datetime(df_movie_details[\"release_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_movie_details[\"release_date\"] < \"2015-01-01\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a2c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movies = df_movie_details[\"movie_id\"].loc[df_movie_details[\"release_date\"] < \"2015-01-01\"]\n",
    "test_movies = df_movie_details[\"movie_id\"].loc[df_movie_details[\"release_date\"] >= \"2015-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b1751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_reviews.groupby('movie_id')[\"is_spoiler\"].value_counts()[\"tt0012349\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7733594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_reviews.loc[df_reviews[\"movie_id\"].isin(train_movies)]\n",
    "df_test = df_reviews.loc[df_reviews[\"movie_id\"].isin(test_movies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_spoiler = df_train.loc[df_reviews['is_spoiler'] == True]\n",
    "df_train_non_spoiler = df_train.loc[df_reviews['is_spoiler'] == False]\n",
    "\n",
    "df_train_non_spoiler = df_train_non_spoiler.sample(n = df_train_spoiler[\"is_spoiler\"].count(), random_state = 42)\n",
    "df_train = pd.concat([df_train_spoiler, df_train_non_spoiler])\n",
    "\n",
    "df_test_spoiler = df_test.loc[df_reviews['is_spoiler'] == True]\n",
    "df_test_non_spoiler = df_test.loc[df_reviews['is_spoiler'] == False]\n",
    "\n",
    "df_test_non_spoiler = df_test_non_spoiler.sample(n = df_test_spoiler[\"is_spoiler\"].count(), random_state = 42)\n",
    "df_test = pd.concat([df_test_spoiler, df_test_non_spoiler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ff83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['is_spoiler'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['is_spoiler'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2babeb1",
   "metadata": {},
   "source": [
    "## 3. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321dfe85",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow_train = vectorizer.fit_transform(df_train[\"text_tokenized\"])\n",
    "bow_test = vectorizer.transform(df_test[\"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1c7ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(max_iter = 1e5)\n",
    "logistic_model.fit(bow_train, df_train[\"is_spoiler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5d04f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_model.score(bow_test, df_test[\"is_spoiler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599d745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(df_test[\"is_spoiler\"], logistic_model.predict(bow_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc7275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(df_test[\"is_spoiler\"], logistic_model.predict(bow_test))).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a314752",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(df_test[\"is_spoiler\"], logistic_model.predict(bow_test))\n",
    "print(classification_report(df_test[\"is_spoiler\"], logistic_model.predict(bow_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel = 'sigmoid', max_iter = 1e4)\n",
    "clf.fit(bow_train, df_train[\"is_spoiler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef49e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(bow_test, df_test[\"is_spoiler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f68ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bow_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.InputLayer(input_shape = (bow_train.shape[1],), sparse = True),\n",
    "                                    tf.keras.layers.Dense(128, activation='relu'),\n",
    "                                    tf.keras.layers.Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ba597",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2695b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coo = bow_train.tocoo()\n",
    "indices = np.mat([coo.row, coo.col]).transpose()\n",
    "sparse_train = tf.SparseTensor(indices, coo.data, coo.shape)\n",
    "\n",
    "coo = bow_test.tocoo()\n",
    "indices = np.mat([coo.row, coo.col]).transpose()\n",
    "sparse_test = tf.SparseTensor(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10455aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(sparse_train, df_train[\"is_spoiler\"].to_numpy(), validation_data = (sparse_test, df_test[\"is_spoiler\"].to_numpy()), epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5fad50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(sparse_train, df_train[\"is_spoiler\"].to_numpy(), verbose = False)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ef9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(sparse_test, df_test[\"is_spoiler\"].to_numpy(), verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(sparse_test, verbose = False) > 0.5\n",
    "y_pred = y_pred.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_test[\"is_spoiler\"], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ed366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(df_test[\"is_spoiler\"], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f556af",
   "metadata": {},
   "source": [
    "### Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35254f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer()\n",
    "tfidf_train = tfidfvectorizer.fit_transform(df_train['text_tokenized'])\n",
    "tfidf_test = tfidfvectorizer.transform(df_test['text_tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ce86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(max_iter = 1e5)\n",
    "logistic_model.fit(tfidf_train, df_train[\"is_spoiler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa78e52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_model.score(tfidf_test, df_test[\"is_spoiler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5578b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='sigmoid', max_iter = 1e4)\n",
    "clf.fit(tfidf_train, df_train['is_spoiler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248494e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(tfidf_test, df_test['is_spoiler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01282f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee323e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_coo_train = tfidf_train.tocoo()\n",
    "indices = np.mat([tfidf_coo_train.row, tfidf_coo_train.col]).transpose()\n",
    "tfidf_sparse_train = tf.SparseTensor(indices, tfidf_coo_train.data, tfidf_coo_train.shape)\n",
    "\n",
    "tfidf_coo_test = tfidf_test.tocoo()\n",
    "indices = np.mat([tfidf_coo_test.row, tfidf_coo_test.col]).transpose()\n",
    "tfidf_sparse_test = tf.SparseTensor(indices, tfidf_coo_test.data, tfidf_coo_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = tf.keras.models.Sequential([tf.keras.layers.InputLayer(input_shape = (tfidf_train.shape[1],), sparse = True),\n",
    "                                    tf.keras.layers.Dense(128, activation='relu'),\n",
    "                                    tf.keras.layers.Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6149723",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9165bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.fit(tfidf_sparse_train, df_train[\"is_spoiler\"].to_numpy(), validation_data = (tfidf_sparse_test, df_test[\"is_spoiler\"].to_numpy()), epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea61c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_test['is_spoiler'], model.predict(sparse_test) > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa18b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(df_test['is_spoiler'], model.predict(sparse_test) > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862437f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
